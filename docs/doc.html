<!doctype html><html><head><meta charset='utf-8'>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/2.4.1/github-markdown.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/styles/default.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
<link rel="stylesheet" href="https://gitcdn.xyz/repo/goessner/mdmath/master/css/mdmath.css">
</head><body class="markdown-body">
<h1>《人工智能导论》实验三实验报告</h1>
<p>计54 陈宇 2015011343</p>
<h2>实验目的</h2>
<p><a href="https://www.kaggle.com/c/digit-recognizer">Digit Recognizer</a>是<a href="https://www.kaggle.com/">Kaggle</a>上的一个手写数字识别比赛，要求选手根据网站提供的训练数据进行训练，然后标注出另一部分待检测图片的数字。</p>
<p>本次实验要求学生参与Digit Recognizer比赛，与世界各地的科学家一较高低，并比较不同算法对于手写数字识别的效果差异。</p>
<h2>最终提交结果展示</h2>
<div align=center><img src="imgs/submissions.png"/></div>
<p>在实验中，我实现了CNN和KNN算法并进行了一些比较，最终CNN的效果最好，<strong>正确率达到了 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn><mi mathvariant="normal">.</mi><mn>9</mn><mn>9</mn><mn>0</mn><mn>8</mn><mn>6</mn></mrow><annotation encoding="application/x-tex">0.99086</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">9</span><span class="mord mathrm">9</span><span class="mord mathrm">0</span><span class="mord mathrm">8</span><span class="mord mathrm">6</span></span></span></span></eq> ，总提交次数为 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">6</span></span></span></span></eq> 次</strong>。</p>
<div align=center>
    <table>
        <thead>
            <tr>
                <th>算法</th>
                <th>正确率</th>
                <th>备注</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>CNN</td><td>0.99086</td><td>训练了一晚上</td>
            </tr>
            <tr>
                <td>CNN(small)</td><td>0.98686</td><td>训练时间较短</td>
            </tr>
            <tr>
                <td>KNN(K=1)</td><td>0.97114</td><td>跑得贼块</td>
            </tr>
            <tr>
                <td>KNN(K=5)</td><td>0.96800</td><td>跑得贼块</td>
            </tr>
            <tr>
                <td>KNN(K=3)</td><td>0.96857</td><td>跑得贼块</td>
            </tr>
        </tbody>
    </table>
</div>
<h2>CNN(卷积神经网络)</h2>
<p>由于我们的问题是识别出一张图片上的数字，对于此类问题，CNN(卷积神经网络)的表现非常优秀，故我在实验中使用Tensorflow构造了一个CNN来解决这个问题，该CNN的数据流图如下：</p>
<div align=center><img src="imgs/CNN1.png"/></div>
<p>该神经网络是仿照MINST的网络构建的，图片向量先经过<code>reshape</code>变成 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn><mn>8</mn><mo>∗</mo><mn>2</mn><mn>8</mn></mrow><annotation encoding="application/x-tex">28*28</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">2</span><span class="mord mathrm">8</span><span class="mbin">∗</span><span class="mord mathrm">2</span><span class="mord mathrm">8</span></span></span></span></eq> 的大小，然后使用 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>3</mn><mn>2</mn></mrow><annotation encoding="application/x-tex">32</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">3</span><span class="mord mathrm">2</span></span></span></span></eq> 个 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>5</mn><mo>∗</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5*5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">5</span><span class="mbin">∗</span><span class="mord mathrm">5</span></span></span></span></eq> 的卷积核进行卷积，之所以选择 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>5</mn><mo>∗</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5*5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">5</span><span class="mbin">∗</span><span class="mord mathrm">5</span></span></span></span></eq> 大小的卷积核，是考虑到输入图片的大小是 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn><mn>8</mn><mo>∗</mo><mn>2</mn><mn>8</mn></mrow><annotation encoding="application/x-tex">28*28</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">2</span><span class="mord mathrm">8</span><span class="mbin">∗</span><span class="mord mathrm">2</span><span class="mord mathrm">8</span></span></span></span></eq> ，为了最终得出的模型具有鲁棒性，能够应对图片的一些旋转和平移，所以卷积核应该大一点，但是如果卷积核太大，很可能会导致图片的不同特征被混在了一起，而且卷积核越大，需要训练的参数也越多，在数据集不变的情况下，会导致训练时间增长且最终结果变差（出现过拟合），综上，最终选定的卷积核大小为 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>5</mn><mo>∗</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5*5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">5</span><span class="mbin">∗</span><span class="mord mathrm">5</span></span></span></span></eq> 。</p>
<p>经过一层卷积之后，数据变成了 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn><mn>8</mn><mo>∗</mo><mn>2</mn><mn>8</mn><mo>∗</mo><mn>3</mn><mn>2</mn></mrow><annotation encoding="application/x-tex">28*28*32</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">2</span><span class="mord mathrm">8</span><span class="mbin">∗</span><span class="mord mathrm">2</span><span class="mord mathrm">8</span><span class="mbin">∗</span><span class="mord mathrm">3</span><span class="mord mathrm">2</span></span></span></span></eq> 的大小，此时将输入送入一个<code>relu</code>层，<code>relu</code>的算法原理是将每个数据和 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">0</span></span></span></span></eq> 取 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">max</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">m</span><span class="mord mathit">a</span><span class="mord mathit">x</span></span></span></span></eq> ，其作用是模拟生物神经元的重激活过程。然后将经过<code>relu</code>的数据送入一个 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn><mo>∗</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">2*2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">2</span><span class="mbin">∗</span><span class="mord mathrm">2</span></span></span></span></eq> 的<code>max pool</code>，其内部原理是对矩阵的每 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn><mo>∗</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">2*2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">2</span><span class="mbin">∗</span><span class="mord mathrm">2</span></span></span></span></eq> 的元素取一个最大值，最终得到的数据大小为 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mn>4</mn><mo>∗</mo><mn>1</mn><mn>4</mn><mo>∗</mo><mn>3</mn><mn>2</mn></mrow><annotation encoding="application/x-tex">14*14*32</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span><span class="mord mathrm">4</span><span class="mbin">∗</span><span class="mord mathrm">1</span><span class="mord mathrm">4</span><span class="mbin">∗</span><span class="mord mathrm">3</span><span class="mord mathrm">2</span></span></span></span></eq> 。<code>max pool</code>在此处充当一个非线性层，其作用是和之前的卷积层相互作用，使得最终测试的图片即使经过一些旋转和平移，<code>max pool</code>层得出的结果也不会相差太大。</p>
<p>只有一层的卷积是不足够的，所以我在上面的基础上再添加了相同的三层（卷积，<code>relu</code>,<code>max pool</code>）。而为什么没有将两个卷积层直接相连，是由于两个连续的线性层和一个线性层是等价的，所以需要使用非线性层(<code>relu</code>,<code>max pool</code>)将其隔开，同理，第二个线性层也需要和之后的全连接层用非线性层隔开。第二个<code>max pool</code>输出的数据是 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>7</mn><mo>∗</mo><mn>7</mn><mo>∗</mo><mn>6</mn><mn>4</mn></mrow><annotation encoding="application/x-tex">7*7*64</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">7</span><span class="mbin">∗</span><span class="mord mathrm">7</span><span class="mbin">∗</span><span class="mord mathrm">6</span><span class="mord mathrm">4</span></span></span></span></eq> 大小的。</p>
<p>在数据集足够的情况下，还可以添加第三个卷积层，但是受限于本实验中的数据集大小，以及三层卷积需要的训练时间太长，所以我在实验中并没有添加更多的卷积层。</p>
<p>经过了两层卷积层之后，再将数据送入一个全连接层，将数据维度变成 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mn>0</mn><mn>2</mn><mn>4</mn></mrow><annotation encoding="application/x-tex">1024</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span><span class="mord mathrm">0</span><span class="mord mathrm">2</span><span class="mord mathrm">4</span></span></span></span></eq> ，此步骤的目的是在前两层卷积的基础上，进一步提取特征，为之后一层做准备。</p>
<p>将上一层全连接的数据再送入一个全连接，将数据唯独变成 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mn>0</mn></mrow><annotation encoding="application/x-tex">10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span><span class="mord mathrm">0</span></span></span></span></eq> ，此层的输出就是最终的输出的。值得一提的是，前面说过两个相邻的线性层和一个线性层的作用是等价的，但是我在此处为什么放置两个相邻的全连接层的？实际上在计算中，这两个全连接层和一个全连接层的效果确实是等价的，但是我在实验中，在第一个全连接层出添加了一个<code>dropout</code>，目的是为了防止出现过拟合的情况，所以在训练中这两层全连接并不等同于一个全连接。</p>
<p>最后，使用<code>softmax</code>进行归一化，得到的 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mn>0</mn></mrow><annotation encoding="application/x-tex">10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span><span class="mord mathrm">0</span></span></span></span></eq> 维向量就是最终每个数字的概率。</p>
<p>在实验中，我使用“交叉熵”（cross-entropy）作为损失函数，其表达式如下：</p>
<div align=center><img src="imgs/cross-entropy.png"/></div>
<p>其中， <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span></span></span></span></eq> 是我们预测的概率分布, <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>y</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow><annotation encoding="application/x-tex">y'</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.751892em;"></span><span class="strut bottom" style="height:0.946332em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mathrm mtight">′</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span></eq> 是实际的分布。</p>
<p>在训练中，我将数据集分成两份，一份是训练集，占总数据集的 <eq>ParseError: KaTeX parse error: Expected 'EOF', got '%' at position 3: 90%̲</eq> ，另一份是测试集，占总数据集的 <eq>ParseError: KaTeX parse error: Expected 'EOF', got '%' at position 3: 10%̲</eq> 。每次迭代放入 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn><mn>0</mn><mn>0</mn></mrow><annotation encoding="application/x-tex">200</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">2</span><span class="mord mathrm">0</span><span class="mord mathrm">0</span></span></span></span></eq> 条数据，迭代了 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mn>0</mn><mn>0</mn><mn>0</mn><mn>0</mn><mn>0</mn></mrow><annotation encoding="application/x-tex">100000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span><span class="mord mathrm">0</span><span class="mord mathrm">0</span><span class="mord mathrm">0</span><span class="mord mathrm">0</span><span class="mord mathrm">0</span></span></span></span></eq> 次，由于使用CPU进行训练太慢，所以我在电脑在晚上训练，第二天早上查看训练结果，由于没有计时，所以并不知道确切的时间，<strong>最终测试正确率为0.99086</strong>。</p>
<p>此外，我在这种模型的基础上做了一些小修改，训练了一个参数量略小的CNN，但是由于CPU训练太慢，导致并没有训练足够的时间，最终测试结果正确率为 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn><mi mathvariant="normal">.</mi><mn>9</mn><mn>8</mn><mn>6</mn><mn>8</mn><mn>6</mn></mrow><annotation encoding="application/x-tex">0.98686</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">9</span><span class="mord mathrm">8</span><span class="mord mathrm">6</span><span class="mord mathrm">8</span><span class="mord mathrm">6</span></span></span></span></eq> ，猜测如果给足训练时间应该和上面的模型正确率差不太多。</p>
<h2>KNN(k-Nearest Neighbor)</h2>
<p>KNN算法也叫K临近，是数据挖掘领域最简单的算法之一，其算法原理可以用如下图片描述：</p>
<div align=center><img src="imgs/KNN.jpg"/></div>
<p>在本实验中，将每张图片看作一个 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>7</mn><mn>8</mn><mn>4</mn></mrow><annotation encoding="application/x-tex">784</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">7</span><span class="mord mathrm">8</span><span class="mord mathrm">4</span></span></span></span></eq> 维空间中的一个点。对于一个需要计算的图片向量，计算空间中离它最近的 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span></span></eq> 个点，然后统计这 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span></span></eq> 个点分别的属性，取出现次数最多的数字作为需要计算图片的数字。</p>
<p>我首先测试了 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="mrel">=</span><span class="mord mathrm">1</span></span></span></span></eq> 的情况，也就是待计算图片的数字取欧式空间中离它最近点的数字。虽然算法非常简单，但是测试结果异常的好，达到了 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn><mi mathvariant="normal">.</mi><mn>9</mn><mn>7</mn><mn>1</mn><mn>1</mn><mn>4</mn></mrow><annotation encoding="application/x-tex">0.97114</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">9</span><span class="mord mathrm">7</span><span class="mord mathrm">1</span><span class="mord mathrm">1</span><span class="mord mathrm">4</span></span></span></span></eq> 。</p>
<p>然后我继续测试了 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">k=5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="mrel">=</span><span class="mord mathrm">5</span></span></span></span></eq> 和 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">k=3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="mrel">=</span><span class="mord mathrm">3</span></span></span></span></eq> 的情况，但是测试结果分别是 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn><mi mathvariant="normal">.</mi><mn>9</mn><mn>6</mn><mn>8</mn><mn>0</mn><mn>0</mn></mrow><annotation encoding="application/x-tex">0.96800</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">9</span><span class="mord mathrm">6</span><span class="mord mathrm">8</span><span class="mord mathrm">0</span><span class="mord mathrm">0</span></span></span></span></eq> 和 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn><mi mathvariant="normal">.</mi><mn>9</mn><mn>6</mn><mn>8</mn><mn>5</mn><mn>7</mn></mrow><annotation encoding="application/x-tex">0.96857</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">9</span><span class="mord mathrm">6</span><span class="mord mathrm">8</span><span class="mord mathrm">5</span><span class="mord mathrm">7</span></span></span></span></eq> ，不仅没有超过 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="mrel">=</span><span class="mord mathrm">1</span></span></span></span></eq> 的情况，最终效果反而变差了。</p>
<h2>实验总结</h2>
<p>从试验结果来看，CNN在图片相关的领域确实如其传闻那样表现优秀，只要有足够的数据量和计算能力，CNN的力量应该是非常强大的。</p>
<p>同时，传统算法在某些时候的表现依然不错，比如KNN能够取得 <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn><mi mathvariant="normal">.</mi><mn>9</mn><mn>7</mn><mn>1</mn><mn>1</mn><mn>4</mn></mrow><annotation encoding="application/x-tex">0.97114</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">9</span><span class="mord mathrm">7</span><span class="mord mathrm">1</span><span class="mord mathrm">1</span><span class="mord mathrm">4</span></span></span></span></eq> 的成绩确实出乎我的意料，然而KNN算法存在瓶颈，它并不能永远在数据量增大的情况下效果变好，很多时候反而会变差，这也是其相比于CNN不足的地方。</p>
<h2>参考文献</h2>
<ul>
<li>百度百科，邻近算法，<a href="http://baike.baidu.com/item/%E9%82%BB%E8%BF%91%E7%AE%97%E6%B3%95/1151153?fromtitle=Knn&amp;fromid=3479559">http://baike.baidu.com/item/邻近算法/1151153?fromtitle=Knn&amp;fromid=3479559</a></li>
<li>Tensorflow中文社区，<a href="http://www.tensorfly.cn/">http://www.tensorfly.cn/</a></li>
</ul>

</body></html>
